# RobustezAdaptativa
En un modelo de clasificación de imágenes, por ejemplo de perros y gatos, se esperaría que la figura de un perro sea clasificada como tal independiente si la imagen es rotada, se cambia el tamaño y/o se alteran la luminosidad.   Sin embargo, hay cierto tipos de contextos donde, dada una función, se esperaría que el modelo cambie la predicción al aplicar algunos tipo de alteraciones en las imágenes, como es el caso de modelos para detectar razas pura-sangre (el color si importa), la posición de un objeto en aplicaciones de robótica, o clasificación de fruta apta para exportación.   Los métodos de robustez sobre modelos de clasificación de imágenes son relativamente nuevos, y están abordando la primera problemática planteada, es decir, estableciendo que la robustez es una propiedad intrínseca del modelo, asociada a la inmutabilidad en la predicción. En nuestra tesis, proponemos un método para evaluar y explicar la robustez en modelos de clasificación de imágenes basadas en el contexto de aplicación, el cual puede adaptarse a distintos escenarios, especificando qué clases y qué tipos de alteraciones deberían entregar una predicción similar a la imagen original y cuales no.
